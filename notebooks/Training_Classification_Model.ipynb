{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ea7f043-d3bc-4ffc-ad0d-d81f5c204589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c70aafbc-6d52-4c9a-89c7-ec5fec4a9d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "prodigy_key = os.getenv(\"MY_PRODIGY_KEY\")\n",
    "if not prodigy_key:\n",
    "    raise ValueError(\"Environment variable MY_PRODIGY_KEY is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981bac62-e1d9-4e4c-ab01-1b83ae1161fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
   ],
   "source": [
    "# Install library and versions below\n",
    "%pip install spacy==3.7.5 spacy-transformers==1.3.5 spacy-loggers==1.0.5 mlflow==2.20.1 > /dev/null 2>&1\n",
    "%pip install prodigy -f https://{prodigy_key}@download.prodi.gy/\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b600d557-6c42-4096-b939-29f1b0682e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Core Utilities\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Data Handling\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# MLflow Components\n",
    "import mlflow\n",
    "import mlflow.spacy\n",
    "\n",
    "# SpaCy / NLP Components\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.training import Example\n",
    "from spacy.training.initialize import init_nlp\n",
    "from spacy.training.loop import train\n",
    "from spacy.util import load_config\n",
    "from spacy.cli.train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c5c312-8d89-41e6-ae6d-485f67fcc529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View the annotated data you've annotated and double-check you've been consistent in your annotation (ESPECIALLY IF MULTIPLE ANNOTATORS DID THE WORK). Changes you should make are:\n",
    "- To change the benefit category applied for an example, use the 'accept' column\n",
    "- To change whether you want to include the example in training or not, use the 'answer' column. 'accept' -> Include in training. 'reject' -> Exclude from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f9625b-3750-4bf4-a778-0cb6ba07bca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Much easier to make changes in excel. Export as csv, then re-load into this notebook to convert back to jsonl\n",
    "\n",
    "annotated_data = \"/v2_1_fixed.jsonl\"\n",
    "df_annotated_data = pd.read_json(annotated_data, lines=True)\n",
    "df_annotated_data.to_csv(annotated_data.replace('.jsonl', '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a60a92-fc91-42a5-a4f5-d285db16e1a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted column 'meta' from string to dictionary.\nConverted column 'config' from string to dictionary.\nConverted column 'accept' from string to list where applicable.\nConverted column 'options' from string to list where applicable.\n"
     ]
    }
   ],
   "source": [
    "# Load back in as csv and convert back to jsonl\n",
    "\n",
    "new_annotated_data = \"/v2_1_fixed.csv\"\n",
    "df_new_annotated_data = pd.read_csv(new_annotated_data)\n",
    "\n",
    "\n",
    "def convert_columns(df):\n",
    "    # Define columns to convert\n",
    "    dictionary_to_convert = ['meta', 'config']\n",
    "    array_to_convert = ['accept', 'options']\n",
    "    \n",
    "    # Convert specified dictionary columns\n",
    "    for column in dictionary_to_convert:\n",
    "        if column in df.columns:\n",
    "            try:\n",
    "                df[column] = df[column].apply(\n",
    "                    lambda x: ast.literal_eval(x) if pd.notnull(x) else x\n",
    "                )\n",
    "                print(f\"Converted column '{column}' from string to dictionary.\")\n",
    "            except (ValueError, SyntaxError) as e:\n",
    "                print(f\"Error converting column '{column}': {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Column '{column}' not found in the DataFrame.\")\n",
    "    \n",
    "    # Convert specified array columns\n",
    "    for column in array_to_convert:\n",
    "        if column in df.columns:\n",
    "            try:\n",
    "                df[column] = df[column].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.strip().startswith('[') else x\n",
    "                )\n",
    "                print(f\"Converted column '{column}' from string to list where applicable.\")\n",
    "            except (ValueError, SyntaxError) as e:\n",
    "                print(f\"Error converting column '{column}': {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Column '{column}' not found in the DataFrame.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "convert_columns(df_new_annotated_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b93d49-b9b8-4a66-a491-96f277a45650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create the 'ground-truth' dataset for this model by combining the previous ground-truth with the additional data you've annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29113fca-d96f-4307-b163-c5a60d029a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 12)\n"
     ]
    }
   ],
   "source": [
    "old_ground_truth = \"/textclass_v2_1.jsonl\"\n",
    "df_old_ground_truth = pd.read_json(old_ground_truth, lines=True)\n",
    "print(df_old_ground_truth.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81714b57-caeb-4d7c-9d94-e6b81efce69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Some checks before training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a94bb59-ea39-4329-ab3f-efb3959430a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Check both datasets have the same group of Benefit Categories we're training - by looking at the 'options' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81f189b-5db3-4b8e-8cb2-0974a5cc90c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both DataFrames have the same 'options' values. Continue.\n"
     ]
    }
   ],
   "source": [
    "def serialize_options(option):\n",
    "    if isinstance(option, dict):\n",
    "        # Sort the dictionary by keys and recursively serialize its values\n",
    "        sorted_dict = {k: serialize_options(v) for k, v in sorted(option.items())}\n",
    "        return json.dumps(sorted_dict, sort_keys=True)\n",
    "    elif isinstance(option, list):\n",
    "        # Recursively serialize each item in the list\n",
    "        serialized_list = [serialize_options(item) for item in option]\n",
    "        # Sort the serialized list to ensure order-independence\n",
    "        serialized_list_sorted = sorted(serialized_list)\n",
    "        return json.dumps(serialized_list_sorted)\n",
    "    else:\n",
    "        # For other data types, serialize directly\n",
    "        return json.dumps(option)\n",
    "\n",
    "# Apply serialization to 'options' columns\n",
    "df_old_ground_truth['options_serialized'] = df_old_ground_truth['options'].apply(serialize_options)\n",
    "df_new_annotated_data['options_serialized'] = df_new_annotated_data['options'].apply(serialize_options)\n",
    "\n",
    "# Convert serialized 'options' to sets\n",
    "old_options_set = set(df_old_ground_truth['options_serialized'])\n",
    "new_options_set = set(df_new_annotated_data['options_serialized'])\n",
    "\n",
    "# Compare the sets\n",
    "if old_options_set == new_options_set:\n",
    "    print(\"Both DataFrames have the same 'options' values. Continue.\")\n",
    "else:\n",
    "    # Identify differences\n",
    "    only_in_old = old_options_set - new_options_set\n",
    "    only_in_new = new_options_set - old_options_set\n",
    "    \n",
    "    # Explain differences\n",
    "    print(\"Differences found in the 'options' column:\")\n",
    "    \n",
    "    if only_in_old:\n",
    "        print(\"Values present only in the old DataFrame:\")\n",
    "        for item in only_in_old:\n",
    "            print(json.loads(item))  # Deserialize for human-readable format\n",
    "    \n",
    "    if only_in_new:\n",
    "        print(\"Values present only in the new DataFrame:\")\n",
    "        for item in only_in_new:\n",
    "            print(json.loads(item))  # Deserialize for human-readable format\n",
    "    \n",
    "    print(\"It is crucial to have them the same. Check the differences above and fix.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca4bd763-cd0e-4cd5-af0c-17c2dd6a363e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Drop those annotated examples that're 'reject' or 'skip' as they wont be used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1950dac1-82fe-4bf9-af00-20944856809a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'df_old_ground_truth': No rows to drop. All 'answer' values are 'accept'.\n'df_new_annotated_data': No rows to drop. All 'answer' values are 'accept'.\n"
     ]
    }
   ],
   "source": [
    "def drop_non_accept_answers(df, df_name='DataFrame'):\n",
    "    # Identify rows where 'answer' is not 'accept'\n",
    "    condition = df['answer'] != 'accept'\n",
    "    rows_to_drop = df[condition]\n",
    "    count_to_drop = rows_to_drop.shape[0]\n",
    "\n",
    "    if count_to_drop > 0:\n",
    "        # Create a filtered DataFrame with the rows to drop\n",
    "        filtered_df = rows_to_drop.copy()\n",
    "\n",
    "        # Drop the identified rows\n",
    "        df.drop(rows_to_drop.index, inplace=True)\n",
    "        print(f\"'{df_name}': Dropped {count_to_drop} row(s) where 'answer' is not 'accept'.\")\n",
    "        print(f\"Check 'filtered_df_{df_name}' to confirm these are supposed to be dropped.\")\n",
    "\n",
    "        return filtered_df\n",
    "    else:\n",
    "        print(f\"'{df_name}': No rows to drop. All 'answer' values are 'accept'.\")\n",
    "        return None\n",
    "    \n",
    "    # Apply the function to df_old_ground_truth\n",
    "filtered_df_df_old_ground_truth = drop_non_accept_answers(df_old_ground_truth, df_name='df_old_ground_truth')\n",
    "\n",
    "# Apply the function to df_new_annotated_data\n",
    "filtered_df_df_new_annotated_data = drop_non_accept_answers(df_new_annotated_data, df_name='df_new_annotated_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43238a21-d39f-411a-ab32-076d75a62537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Final check to make sure columns are all same and in consistent format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f921a54-0f75-41f7-aad1-9e53cb659f04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both DataFrames have the same column names in the same order.\n"
     ]
    }
   ],
   "source": [
    "def compare_and_clean_columns(df1, df2, df1_name='df1', df2_name='df2'):\n",
    "    columns_df1 = set(df1.columns)\n",
    "    columns_df2 = set(df2.columns)\n",
    "\n",
    "    # Check if columns are the same\n",
    "    if list(df1.columns) == list(df2.columns):\n",
    "        print(\"Both DataFrames have the same column names in the same order.\")\n",
    "    else:\n",
    "        print(\"DataFrames have different column names or different column orders.\")\n",
    "        \n",
    "        # Identify extra and missing columns\n",
    "        extra_in_df1 = columns_df1 - columns_df2\n",
    "        extra_in_df2 = columns_df2 - columns_df1\n",
    "        common_columns = columns_df1 & columns_df2\n",
    "\n",
    "        if extra_in_df1:\n",
    "            print(f\"\\nColumns only in {df1_name}:\")\n",
    "            for col in extra_in_df1:\n",
    "                print(f\" - {col}\")\n",
    "        else:\n",
    "            print(f\"\\nNo extra columns in {df1_name}.\")\n",
    "\n",
    "        if extra_in_df2:\n",
    "            print(f\"\\nColumns only in {df2_name}:\")\n",
    "            for col in extra_in_df2:\n",
    "                print(f\" - {col}\")\n",
    "        else:\n",
    "            print(f\"\\nNo extra columns in {df2_name}.\")\n",
    "\n",
    "        # Check for column order differences\n",
    "        if common_columns:\n",
    "            ordered_common_df1 = [col for col in df1.columns if col in common_columns]\n",
    "            ordered_common_df2 = [col for col in df2.columns if col in common_columns]\n",
    "            if ordered_common_df1 != ordered_common_df2:\n",
    "                print(\"\\nCommon columns are in different orders:\")\n",
    "                print(f\" - {df1_name} order: {ordered_common_df1}\")\n",
    "                print(f\" - {df2_name} order: {ordered_common_df2}\")\n",
    "            else:\n",
    "                print(\"\\nCommon columns are in the same order.\")\n",
    "\n",
    "compare_and_clean_columns(\n",
    "    df_old_ground_truth, \n",
    "    df_new_annotated_data, \n",
    "    df1_name='df_old_ground_truth', \n",
    "    df2_name='df_new_annotated_data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92fe35d0-8ece-4101-a363-0a2f94aec04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prep training materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac3d4f9-1f9c-4a53-a5a6-84e8b9544e78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in df_new_ground_truth is correct.\n"
     ]
    }
   ],
   "source": [
    "# Combining datasets to create new_ground_truth\n",
    "df_new_ground_truth = pd.concat([df_old_ground_truth,df_new_annotated_data])\n",
    "\n",
    "expected_rows = df_old_ground_truth.shape[0] + df_new_annotated_data.shape[0]\n",
    "actual_rows = df_new_ground_truth.shape[0]\n",
    "\n",
    "if expected_rows == actual_rows:\n",
    "    print(\"The number of rows in df_new_ground_truth is correct.\")\n",
    "else:\n",
    "    print(\"The number of rows in df_new_ground_truth is incorrect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10f1e49-82c3-4744-9119-949a7cf28399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save as jsonl as needed to feed into training\n",
    "\n",
    "ground_truth_path = \"/v2.test_ground_truth.jsonl\"\n",
    "\n",
    "df_new_ground_truth.to_json(ground_truth_path,lines=True,orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef01589-075b-4e0e-a4b8-99f15a3e2c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
   ],
   "source": [
    "# INSTRUCTION: Name the prodigy session you're creating to house the training data for this model (temporarily) e.g. benefits_textcat_v2.2\n",
    "\n",
    "prodigy_session_name = \"benefits_textcat_v2.2\"\n",
    "\n",
    "!python -m prodigy db-in $prodigy_session_name \"$df_new_ground_truth\" --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b56516a-f2cb-4edb-8f4b-aab4886805fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
   ],
   "source": [
    "# Keep training split at 0.1 (90 training : 10 evaluation) unless want more evaluation data\n",
    "\n",
    "training_data_path = \"/Notebooks\"\n",
    "\n",
    "!python -m prodigy data-to-spacy \"$training_data_path\" --textcat-multilabel $prodigy_session_name --eval-split 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "092e8147-af0d-4355-b236-ce558ef7b6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a folder in your DBFS to hold the trained model. Since the model is big, prefer to store in DBFS\n",
    "\n",
    "dbutils.fs.mkdirs('/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691867ea-2adb-4ed8-a787-8622ce93e524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Output of your DBFS folder for the model\n",
    "output_path = Path(\"/temp\")\n",
    "\n",
    "# dev.spacy and train'spacy files produced from the above 'data-to-spacy' command you ran\n",
    "train_path = \"/train.spacy\"\n",
    "dev_path = \"/dev.spacy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8b7fcff-2576-4e5d-9e2a-1380ce804ed2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_path = \"/textcat_config_v2.cfg\"\n",
    "local_model_path = \"/jdbert-384\"\n",
    "\n",
    "overrides = {\n",
    "    \"paths.train\": train_path,\n",
    "    \"paths.dev\": dev_path,\n",
    "    \"paths.ground_truth\": ground_truth_path,\n",
    "    \"variables.transformer_model_name\": local_model_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fe22b7d-c1b6-48cc-baa0-baa06bb5da30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Saving to output directory:\n[0m\n\u001B[38;5;4mℹ Using CPU\u001B[0m\n\u001B[1m\n=========================== Initializing pipeline ===========================\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Initialized pipeline\u001B[0m\n\u001B[1m\n============================= Training pipeline =============================\u001B[0m\n\u001B[38;5;4mℹ Pipeline: ['transformer', 'textcat_multilabel']\u001B[0m\n\u001B[38;5;4mℹ Initial learn rate: 0.0\u001B[0m\nE    #       LOSS TRANS...  LOSS TEXTC...  CATS_SCORE  SCORE \n---  ------  -------------  -------------  ----------  ------\n  0       0          30.13           1.22        1.83    0.02\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f98f1b4811433e86908b71b0f1ba9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4     200        3977.16          66.68       19.94    0.20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1567f8d88c72423396e79e905e8f58ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10     400         303.21          10.38       62.79    0.63\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db33ef3964644113b3fd63c8831041b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15     600         263.32           5.33       70.61    0.71\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1c5f8809fb443fab38f25843a93766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20     800         181.98           3.17       74.65    0.75\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87018364bbfd45c297b3f2cfa0a04584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25    1000         121.68           1.83       81.89    0.82\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfcfd9f695e41198ae5f4a9bd4fe888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30    1200          88.17           1.32       83.74    0.84\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271e7bf96ed24da8826401ed262e3697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34    1400          68.43           0.85       83.38    0.83\n 39    1600          53.64           0.70       84.28    0.84\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeb8c044325416cb3e7b3ecd55656bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run to train model. View the experiment and use the 'run_id' to call the best model from this training\n",
    "train(config_path, output_path, overrides=overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de5a66c8-9f2f-46dd-81f4-e80e8c4b3faa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Now we've trained and saved our Benefits Text Categorisation model within MLFlow. All that's needed to use this model in the future is the unique 'run_id'! Easy peasy."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(git) (PROD) Training Benefits Text Categorisation Model - 2. Training model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
